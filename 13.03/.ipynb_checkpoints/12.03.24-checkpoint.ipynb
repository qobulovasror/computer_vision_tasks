{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c81bf7-9587-4f27-8357-f4f225685a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9294950c-5e2b-457c-bcd3-14dd5ab32047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread('img.jpg')\n",
    "# while True:\n",
    "#     cv2.imshow('mandrill',img)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2af398-6ad8-4848-bff0-d98b6d647272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the image to be tested\n",
    "# test_image = cv2.imread('img3.jpg')\n",
    "#Converting to grayscale\n",
    "# test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "# Displaying the grayscale image\n",
    "# plt.imshow(test_image_gray, cmap='gray')\n",
    "#Since we know that OpenCV loads an image in BGR format, so we need to convert it into RBG format to be able to display its true colors. Let us write a small function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3d95f4-adbb-4a72-9c65-77a15d4c1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d5f177-297b-49d3-a073-4c76aa5757ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_cascade_face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "haar_cascade_eyes = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')\n",
    "# haar_cascade_face = cv2.CascadeClassifier('haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb087158-deb1-4e8e-80c9-f82a9a61be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faces_rects = haar_cascade_face.detectMultiScale(test_image_gray, scaleFactor = 1.2, minNeighbors = 5);\n",
    "# Let us print the no. of faces found\n",
    "# print('Faces found: ', len(faces_rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e952d1-d151-4a9d-8bcd-6a8c1a0b184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x,y,w,h) in faces_rects:\n",
    "#      cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0035f121-ee15-4ed7-8f66-9e44c3850c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(convertToRGB(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1124e0ba-7f2b-44ec-8850-0fa916af427c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    canny = cv2.Canny(blur, 10, 70)\n",
    "    ret, mask = cv2.threshold(canny, 70, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Video feed', mask)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f377b0-c7ab-41b9-967f-b88c2924b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2, sys, numpy, os \n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(haar_file) \n",
    "webcam = cv2.VideoCapture(0) \n",
    "\n",
    "# The program loops until it has 30 images of the face. \n",
    "count = 1\n",
    "while count < 30: \n",
    "\t(_, im) = webcam.read() \n",
    "\tgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
    "\tfaces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
    "\tfor (x, y, w, h) in faces: \n",
    "\t\tcv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "\t\tface = gray[y:y + h, x:x + w] \n",
    "\t\tface_resize = cv2.resize(face, (w, h)) \n",
    "\t\tcv2.imwrite('% s/% s.png' % (path, count), face_resize) \n",
    "\tcount += 1\n",
    "\t\n",
    "\tcv2.imshow('OpenCV', im) \n",
    "\tkey = cv2.waitKey(10) \n",
    "\tif key == 13: \n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef744396-907c-45cf-b1d7-4b823fe9fce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Web kamerani ochish\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Web kamerani ochib bo'lganini tekshirish\n",
    "if not cap.isOpened():\n",
    "    print(\"Web kamera topilmadi. Dastur to'xtatiladi.\")\n",
    "    exit()\n",
    "\n",
    "# Face detection uchun modelni yuklash\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    # Kameradan kadrlarni olish\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Kameradan kadrlar olinmadi.\")\n",
    "        break\n",
    "\n",
    "    # Kadrdagi yuzlar\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Yuzlarni belgilash\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Ekran chiqarish\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Dasturni to'xtatish uchun 'q' tugmasini kuzatish\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Qo'riqni tozalash va yopish\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d7891e-1095-4cf9-b245-cc4d55eeb63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "image = cv2.imread(\"car.jpg\")\n",
    "\n",
    "def detectPlateRough(image_gray,resize_h = 720,en_scale =1.08 ,top_bottom_padding_rate = 0.05):\n",
    "        if top_bottom_padding_rate>0.2:\n",
    "            print(\"error:top_bottom_padding_rate > 0.2:\",top_bottom_padding_rate)\n",
    "            exit(1)\n",
    "        height = image_gray.shape[0]\n",
    "        padding = int(height*top_bottom_padding_rate)\n",
    "        scale = image_gray.shape[1]/float(image_gray.shape[0])\n",
    "        image = cv2.resize(image_gray, (int(scale*resize_h), resize_h))\n",
    "        image_color_cropped = image[padding:resize_h-padding,0:image_gray.shape[1]]\n",
    "        image_gray = cv2.cvtColor(image_color_cropped,cv2.COLOR_RGB2GRAY)\n",
    "        watches = watch_cascade.detectMultiScale(image_gray, en_scale, 2, minSize=(36, 9),maxSize=(36*40, 9*40))\n",
    "        cropped_images = []\n",
    "        for (x, y, w, h) in watches:\n",
    "\n",
    "            #cv2.rectangle(image_color_cropped, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "\n",
    "            x -= w * 0.14\n",
    "            w += w * 0.28\n",
    "            y -= h * 0.15\n",
    "            h += h * 0.3\n",
    "\n",
    "            #cv2.rectangle(image_color_cropped, (int(x), int(y)), (int(x + w), int(y + h)), (0, 0, 255), 1)\n",
    "\n",
    "            cropped = cropImage(image_color_cropped, (int(x), int(y), int(w), int(h)))\n",
    "            cropped_images.append([cropped,[x, y+padding, w, h]])\n",
    "            #cv2.imshow(\"imageShow\", cropped)\n",
    "            #cv2.waitKey(0)\n",
    "        return cropped_images\n",
    "\n",
    "def cropImage(image,rect):\n",
    "        cv2.imshow(\"imageShow\", image)\n",
    "        cv2.waitKey(0)\n",
    "        x, y, w, h = computeSafeRegion(image.shape,rect)\n",
    "        cv2.imshow(\"imageShow\", image[y:y+h,x:x+w])\n",
    "        cv2.waitKey(0)\n",
    "        return image[y:y+h,x:x+w]\n",
    "\n",
    "\n",
    "def computeSafeRegion(shape,bounding_rect):\n",
    "        top = bounding_rect[1] # y\n",
    "        bottom  = bounding_rect[1] + bounding_rect[3] # y +  h\n",
    "        left = bounding_rect[0] # x\n",
    "        right =   bounding_rect[0] + bounding_rect[2] # x +  w\n",
    "        min_top = 0\n",
    "        max_bottom = shape[0]\n",
    "        min_left = 0\n",
    "        max_right = shape[1]\n",
    "\n",
    "        #print(left,top,right,bottom)\n",
    "        #print(max_bottom,max_right)\n",
    "\n",
    "        if top < min_top:\n",
    "            top = min_top\n",
    "        if left < min_left:\n",
    "            left = min_left\n",
    "        if bottom > max_bottom:\n",
    "            bottom = max_bottom\n",
    "        if right > max_right:\n",
    "            right = max_right\n",
    "        return [left,top,right-left,bottom-top]   \n",
    "\n",
    "images = detectPlateRough(image,image.shape[0],top_bottom_padding_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2494d4ff-482d-408e-a2f6-e976d87bba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vedio.mp4')\n",
    "car_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "\n",
    "while True:\n",
    "     # reads frames from a video\n",
    "     ret, frames = cap.read()\n",
    "     # convert to gray scale of each frames\n",
    "     gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n",
    "     # Detects cars of different sizes in the input image\n",
    "     cars = car_cascade.detectMultiScale( gray, 1.1, 1)\n",
    "     # To draw a rectangle in each cars\n",
    "     for (x,y,w,h) in cars:\n",
    "         cv2.rectangle(frames,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "     font = cv2.FONT_HERSHEY_DUPLEX\n",
    "     cv2.putText(frames, 'car', (x + 6, y - 6), font, 0.5, (0, 0, 255), 1)\n",
    "     # Display frames in a window\n",
    "     cv2.imshow('Car Detection', frames)\n",
    "     # Wait for Enter key to stop\n",
    "     if cv2.waitKey(33) == 13:\n",
    "         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c81bf7-9587-4f27-8357-f4f225685a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9294950c-5e2b-457c-bcd3-14dd5ab32047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread('img.jpg')\n",
    "# while True:\n",
    "#     cv2.imshow('mandrill',img)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2af398-6ad8-4848-bff0-d98b6d647272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the image to be tested\n",
    "# test_image = cv2.imread('img3.jpg')\n",
    "#Converting to grayscale\n",
    "# test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "# Displaying the grayscale image\n",
    "# plt.imshow(test_image_gray, cmap='gray')\n",
    "#Since we know that OpenCV loads an image in BGR format, so we need to convert it into RBG format to be able to display its true colors. Let us write a small function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3d95f4-adbb-4a72-9c65-77a15d4c1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToRGB(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d5f177-297b-49d3-a073-4c76aa5757ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_cascade_face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "haar_cascade_eyes = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')\n",
    "# haar_cascade_face = cv2.CascadeClassifier('haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb087158-deb1-4e8e-80c9-f82a9a61be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faces_rects = haar_cascade_face.detectMultiScale(test_image_gray, scaleFactor = 1.2, minNeighbors = 5);\n",
    "# Let us print the no. of faces found\n",
    "# print('Faces found: ', len(faces_rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e952d1-d151-4a9d-8bcd-6a8c1a0b184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x,y,w,h) in faces_rects:\n",
    "#      cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0035f121-ee15-4ed7-8f66-9e44c3850c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(convertToRGB(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1124e0ba-7f2b-44ec-8850-0fa916af427c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    canny = cv2.Canny(blur, 10, 70)\n",
    "    ret, mask = cv2.threshold(canny, 70, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Video feed', mask)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f377b0-c7ab-41b9-967f-b88c2924b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2, sys, numpy, os \n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(haar_file) \n",
    "webcam = cv2.VideoCapture(0) \n",
    "\n",
    "# The program loops until it has 30 images of the face. \n",
    "count = 1\n",
    "while count < 30: \n",
    "\t(_, im) = webcam.read() \n",
    "\tgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
    "\tfaces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
    "\tfor (x, y, w, h) in faces: \n",
    "\t\tcv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
    "\t\tface = gray[y:y + h, x:x + w] \n",
    "\t\tface_resize = cv2.resize(face, (w, h)) \n",
    "\t\tcv2.imwrite('% s/% s.png' % (path, count), face_resize) \n",
    "\tcount += 1\n",
    "\t\n",
    "\tcv2.imshow('OpenCV', im) \n",
    "\tkey = cv2.waitKey(10) \n",
    "\tif key == 13: \n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef744396-907c-45cf-b1d7-4b823fe9fce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Web kamerani ochish\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Web kamerani ochib bo'lganini tekshirish\n",
    "if not cap.isOpened():\n",
    "    print(\"Web kamera topilmadi. Dastur to'xtatiladi.\")\n",
    "    exit()\n",
    "\n",
    "# Face detection uchun modelni yuklash\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    # Kameradan kadrlarni olish\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Kameradan kadrlar olinmadi.\")\n",
    "        break\n",
    "\n",
    "    # Kadrdagi yuzlar\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Yuzlarni belgilash\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Ekran chiqarish\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Dasturni to'xtatish uchun 'q' tugmasini kuzatish\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Qo'riqni tozalash va yopish\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d7891e-1095-4cf9-b245-cc4d55eeb63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "watch_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "image = cv2.imread(\"car.jpg\")\n",
    "\n",
    "def detectPlateRough(image_gray,resize_h = 720,en_scale =1.08 ,top_bottom_padding_rate = 0.05):\n",
    "        if top_bottom_padding_rate>0.2:\n",
    "            print(\"error:top_bottom_padding_rate > 0.2:\",top_bottom_padding_rate)\n",
    "            exit(1)\n",
    "        height = image_gray.shape[0]\n",
    "        padding = int(height*top_bottom_padding_rate)\n",
    "        scale = image_gray.shape[1]/float(image_gray.shape[0])\n",
    "        image = cv2.resize(image_gray, (int(scale*resize_h), resize_h))\n",
    "        image_color_cropped = image[padding:resize_h-padding,0:image_gray.shape[1]]\n",
    "        image_gray = cv2.cvtColor(image_color_cropped,cv2.COLOR_RGB2GRAY)\n",
    "        watches = watch_cascade.detectMultiScale(image_gray, en_scale, 2, minSize=(36, 9),maxSize=(36*40, 9*40))\n",
    "        cropped_images = []\n",
    "        for (x, y, w, h) in watches:\n",
    "\n",
    "            #cv2.rectangle(image_color_cropped, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "\n",
    "            x -= w * 0.14\n",
    "            w += w * 0.28\n",
    "            y -= h * 0.15\n",
    "            h += h * 0.3\n",
    "\n",
    "            #cv2.rectangle(image_color_cropped, (int(x), int(y)), (int(x + w), int(y + h)), (0, 0, 255), 1)\n",
    "\n",
    "            cropped = cropImage(image_color_cropped, (int(x), int(y), int(w), int(h)))\n",
    "            cropped_images.append([cropped,[x, y+padding, w, h]])\n",
    "            #cv2.imshow(\"imageShow\", cropped)\n",
    "            #cv2.waitKey(0)\n",
    "        return cropped_images\n",
    "\n",
    "def cropImage(image,rect):\n",
    "        cv2.imshow(\"imageShow\", image)\n",
    "        cv2.waitKey(0)\n",
    "        x, y, w, h = computeSafeRegion(image.shape,rect)\n",
    "        cv2.imshow(\"imageShow\", image[y:y+h,x:x+w])\n",
    "        cv2.waitKey(0)\n",
    "        return image[y:y+h,x:x+w]\n",
    "\n",
    "\n",
    "def computeSafeRegion(shape,bounding_rect):\n",
    "        top = bounding_rect[1] # y\n",
    "        bottom  = bounding_rect[1] + bounding_rect[3] # y +  h\n",
    "        left = bounding_rect[0] # x\n",
    "        right =   bounding_rect[0] + bounding_rect[2] # x +  w\n",
    "        min_top = 0\n",
    "        max_bottom = shape[0]\n",
    "        min_left = 0\n",
    "        max_right = shape[1]\n",
    "\n",
    "        #print(left,top,right,bottom)\n",
    "        #print(max_bottom,max_right)\n",
    "\n",
    "        if top < min_top:\n",
    "            top = min_top\n",
    "        if left < min_left:\n",
    "            left = min_left\n",
    "        if bottom > max_bottom:\n",
    "            bottom = max_bottom\n",
    "        if right > max_right:\n",
    "            right = max_right\n",
    "        return [left,top,right-left,bottom-top]   \n",
    "\n",
    "images = detectPlateRough(image,image.shape[0],top_bottom_padding_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2494d4ff-482d-408e-a2f6-e976d87bba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vedio.mp4')\n",
    "car_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "\n",
    "while True:\n",
    "     # reads frames from a video\n",
    "     ret, frames = cap.read()\n",
    "     # convert to gray scale of each frames\n",
    "     gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n",
    "     # Detects cars of different sizes in the input image\n",
    "     cars = car_cascade.detectMultiScale( gray, 1.1, 1)\n",
    "     # To draw a rectangle in each cars\n",
    "     for (x,y,w,h) in cars:\n",
    "         cv2.rectangle(frames,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "     font = cv2.FONT_HERSHEY_DUPLEX\n",
    "     cv2.putText(frames, 'car', (x + 6, y - 6), font, 0.5, (0, 0, 255), 1)\n",
    "     # Display frames in a window\n",
    "     cv2.imshow('Car Detection', frames)\n",
    "     # Wait for Enter key to stop\n",
    "     if cv2.waitKey(33) == 13:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7d28b9-f63f-4c66-8caf-b970c59c551a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (234244244.py, line 180)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 180\u001b[0;36m\u001b[0m\n\u001b[0;31m    lpr_max_len=lpr_max_le\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from colour_detection.detect_color import detect_color\n",
    "from lpr_net.model.lpr_net import build_lprnet\n",
    "from lpr_net.rec_plate import rec_plate, CHARS\n",
    "from object_detection.detect_car_YOLO import ObjectDetection\n",
    "from track_logic import *\n",
    "\n",
    "import settings\n",
    "\n",
    "def get_frames(video_src: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Генератор, котрый читает видео и отдает фреймы\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_src)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            yield frame\n",
    "        else:\n",
    "            print(\"End video\")\n",
    "            break\n",
    "    return None\n",
    "\n",
    "\n",
    "def preprocess(image: np.ndarray, size: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Препроцесс перед отправкой на YOLO\n",
    "    Ресайз, нормализация и т.д.\n",
    "    \"\"\"\n",
    "    image = cv2.resize(\n",
    "        image, size, fx=0, fy=0, interpolation=cv2.INTER_CUBIC  # resolution\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_boxes(results, frame):\n",
    "\n",
    "    \"\"\"\n",
    "    return dict with labels and cords\n",
    "    :param results: inferences made by model\n",
    "    :param frame: frame on which cords calculated\n",
    "    :return: dict with labels and cords\n",
    "    \"\"\"\n",
    "\n",
    "    labels, cord = results\n",
    "\n",
    "    n = len(labels)\n",
    "    x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "\n",
    "    labls_cords = {}\n",
    "    numbers = []\n",
    "    cars = []\n",
    "    trucks = []\n",
    "    buses = []\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        row = cord[i]\n",
    "        x1, y1, x2, y2 = (\n",
    "            int(row[0] * x_shape),\n",
    "            int(row[1] * y_shape),\n",
    "            int(row[2] * x_shape),\n",
    "            int(row[3] * y_shape),\n",
    "        )\n",
    "\n",
    "        if labels[i] == 0:\n",
    "            numbers.append((x1, y1, x2, y2))\n",
    "        elif labels[i] == 1:\n",
    "            cars.append((x1, y1, x2, y2))\n",
    "        elif labels[i] == 2:\n",
    "            trucks.append((x1, y1, x2, y2))\n",
    "        elif labels[i] == 3:\n",
    "            buses.append((x1, y1, x2, y2))\n",
    "\n",
    "    labls_cords[\"numbers\"] = numbers\n",
    "    labls_cords[\"cars\"] = cars\n",
    "    labls_cords[\"trucks\"] = trucks\n",
    "    labls_cords[\"busses\"] = buses\n",
    "\n",
    "    return labls_cords\n",
    "\n",
    "\n",
    "def plot_boxes(cars_list: list, frame: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    n = len(cars_list)\n",
    "\n",
    "    for car in cars_list:\n",
    "\n",
    "        car_type = car[2]\n",
    "\n",
    "        x1_number, y1_number, x2_number, y2_number = car[0][0]\n",
    "        number = car[0][1]\n",
    "\n",
    "        x1_car, y1_car, x2_car, y2_car = car[1][0]\n",
    "        colour = car[1][1]\n",
    "\n",
    "        if car_type == \"car\":\n",
    "            car_bgr = (0, 0, 255)\n",
    "        elif car_type == \"truck\":\n",
    "            car_bgr = (0, 255, 0)\n",
    "        elif car_type == \"bus\":\n",
    "            car_bgr = (255, 0, 0)\n",
    "\n",
    "        number_bgr = (255, 255, 255)\n",
    "\n",
    "        cv2.rectangle(frame, (x1_car, y1_car), (x2_car, y2_car), car_bgr, 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            car_type + \" \" + colour,\n",
    "            (x1_car, y2_car + 15),\n",
    "            0,\n",
    "            1,\n",
    "            car_bgr,\n",
    "            thickness=2,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.rectangle(\n",
    "            frame, (x1_number, y1_number), (x2_number, y2_number), number_bgr, 2\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            number,\n",
    "            (x1_number - 20, y2_number + 30),\n",
    "            0,\n",
    "            1,\n",
    "            number_bgr,\n",
    "            thickness=2,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    detection_area = settings.DETECTION_AREA\n",
    "\n",
    "    cv2.rectangle(frame, detection_area[0], detection_area[1], (0, 0, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def check_roi(coords):\n",
    "\n",
    "    detection_area = settings.DETECTION_AREA\n",
    "\n",
    "    xc = int((coords[0] + coords[2]) / 2)\n",
    "    yc = int((coords[1] + coords[3]) / 2)\n",
    "    if (\n",
    "        (detection_area[0][0] < xc < detection_area[1][0]) \n",
    "        and \n",
    "        (detection_area[0][1] < yc < detection_area[1][1])\n",
    "        ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def main(\n",
    "    video_file_path, \n",
    "    yolo_model_path,\n",
    "    yolo_conf, \n",
    "    yolo_iou,\n",
    "    lpr_model_path,\n",
    "    lpr_max_len,\n",
    "    lpr_dropout_rate, \n",
    "    device\n",
    "    ):\n",
    "\n",
    "    cv2.startWindowThread()\n",
    "    detector = ObjectDetection(\n",
    "        yolo_model_path, \n",
    "        conf=yolo_conf, \n",
    "        iou=yolo_iou,\n",
    "        device = device\n",
    "        )\n",
    "\n",
    "    LPRnet = build_lprnet(\n",
    "        lpr_max_len=lpr_max_le"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
